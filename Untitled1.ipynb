{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb69c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilaydaonur/opt/anaconda3/lib/python3.8/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue  \n",
    "import speech_recognition as sr\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "r = sr.Recognizer()\n",
    "audio_queue = Queue()\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "r.non_speaking_duration = 0.2\n",
    "r.pause_threshold = 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3833337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_worker():\n",
    "    # this runs in a background thread\n",
    "    while True:\n",
    "        audio = audio_queue.get()  # retrieve the next audio processing job from the main thread\n",
    "        if audio is None: break  # stop processing if the main thread is done\n",
    "\n",
    "        # received audio data, now we'll recognize it using Google Speech Recognition\n",
    "        try:\n",
    "            print('RECOGNIZE\\n')\n",
    "            # for testing purposes, we're just using the default API key\n",
    "            # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "            # instead of `r.recognize_google(audio)`\n",
    "            phrase = r.recognize_google(audio)\n",
    "            print(phrase)\n",
    "            print('TRANSLATE\\n')\n",
    "            print(translator(phrase))\n",
    "        except Exception :\n",
    "            pass\n",
    "        audio_queue.task_done()  # mark the audio processing job as completed in the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533375a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LISTENING\n",
      "\n",
      "LISTENING\n",
      "RECOGNIZE\n",
      "\n",
      "\n",
      "LISTENING\n",
      "\n",
      "if exercises helte why do many people dislike or avoided if we're born to walk and run why do most of us take it easy whenever possible\n",
      "TRANSLATE\n",
      "\n",
      "[{'translation_text': 'si ejercicios helte por qué mucha gente no le gusta o evita si nacemos para caminar y correr ¿por qué la mayoría de nosotros tomarlo con calma siempre que sea posible'}]\n",
      "RECOGNIZE\n",
      "\n",
      "LISTENING\n",
      "RECOGNIZE\n",
      "\n",
      "\n",
      "does running\n",
      "TRANSLATE\n",
      "\n",
      "[{'translation_text': 'se ejecuta'}]\n",
      "LISTENING\n",
      "RECOGNIZE\n",
      "\n",
      "\n",
      "ruin your knees\n",
      "TRANSLATE\n",
      "\n",
      "[{'translation_text': 'Arruina tus rodillas.'}]\n",
      "LISTENING\n",
      "RECOGNIZE\n",
      "\n",
      "\n",
      "okay okay yeah I think I think this is maybe I mean it it just kind of like\n",
      "TRANSLATE\n",
      "\n",
      "[{'translation_text': 'Vale, vale, sí, creo que creo que esto es tal vez lo digo en serio.'}]\n"
     ]
    }
   ],
   "source": [
    "# start a new thread to recognize audio, while this thread focuses on listening\n",
    "recognize_thread = Thread(target=recognize_worker)\n",
    "recognize_thread.daemon = True\n",
    "recognize_thread.start()\n",
    "with sr.Microphone() as source:\n",
    "    try:\n",
    "        while True:  # repeatedly listen for phrases and put the resulting audio on the audio processing job queue\n",
    "            print('LISTENING\\n')\n",
    "            audio_queue.put(r.listen(source))\n",
    "    except KeyboardInterrupt:  # allow Ctrl + C to shut down the program\n",
    "        pass\n",
    "\n",
    "audio_queue.join()  # block until all current audio processing jobs are done\n",
    "audio_queue.put(None)  # tell the recognize_thread to stop\n",
    "recognize_thread.join()  # wait for the recognize_thread to actually stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a89da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "import os \n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def evaluate(test_audio_dir, test_result_dir):\n",
    "    '''\n",
    "        @param test_audio_dir : directory to test .wav files\n",
    "        @param test_result_dir: directory to resulting translation scripts\n",
    "    '''\n",
    "    score = 0\n",
    "    for fname in os.listdir(test_audio_dir):\n",
    "        audio_path = os.path.join(test_audio_dir,fname)\n",
    "        if '.wav' in fname:\n",
    "            without_ext = fname.split('.wav')[0]\n",
    "            audio = sr.AudioFile(audio_path)\n",
    "        elif '.mp4' in fname:\n",
    "            without_ext = fname.split('.mp4')[0]\n",
    "            # convert mp4 to wav\n",
    "            sound = AudioSegment.from_file(audio_path,format=\"mp4\")\n",
    "            sound.export(os.path.join(test_audio_dir,without_ext), format=\"wav\")\n",
    "            audio = sr.AudioFile(os.path.join(test_audio_dir,without_ext))\n",
    "            \n",
    "        ground_truth_file = os.path.join(test_result_dir,without_ext+'.txt')\n",
    "        ground_truth = open(ground_truth_file,'r').readlines()[0]\n",
    "\n",
    "        with audio as source:\n",
    "            audio = r.record(source)\n",
    "        phrase = r.recognize_google(audio)\n",
    "\n",
    "        result = translator(phrase)[0]['translation_text']\n",
    "\n",
    "        score += sentence_bleu(ground_truth.split(),result.split())\n",
    "\n",
    "    return score/len(os.listdir(test_audio_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c47e3886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If exercise is healthy, why many people dislike or avoide it? If we are born to walk and run, why do most of us take it easy whenever possible?\n",
      "if exercise is healthy why do many people dislike or avoided if we're born to walk and run why do most of us take it easy whenever possible\n",
      "Si el ejercicio es saludable ¿por qué a mucha gente le desagrada o evita si nacemos para caminar y correr? ¿Por qué la mayoría de nosotros lo tomamos con calma siempre que sea posible?\n",
      "9.929306298309508e-232\n",
      "If exercise is healthy, why many people dislike or avoide it? If we are born to walk and run, why do most of us take it easy whenever possible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilaydaonur/opt/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/ilaydaonur/opt/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/ilaydaonur/opt/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/78/8jj6w80s633fj05cc_j_1sv40000gn/T/ipykernel_73954/2298605084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'res'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/78/8jj6w80s633fj05cc_j_1sv40000gn/T/ipykernel_73954/1858345734.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(test_audio_dir, test_result_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc551c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482371a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
